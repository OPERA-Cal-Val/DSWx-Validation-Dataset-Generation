{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Staging Upload to ImageCalc Table\n",
    "This notebook goes through an example of uploading a classified planet image, a logfile, and training data to the DSWx calval database. Data files and metadata are uploading to a staging bucket. Then, the database manager will commit these uploads to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.738042Z",
     "start_time": "2022-09-19T22:24:45.155391Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.insert(0, './tools/')\n",
    "from addImageCalc import addImageCalc\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.742743Z",
     "start_time": "2022-09-19T22:24:45.740215Z"
    }
   },
   "outputs": [],
   "source": [
    "#Only specify one. Leave the other as ''. If more than one planet image for given chip, PLANET_ID must be specified \n",
    "PLANET_ID = '20211003_161639_91_241d'\n",
    "SITE_NAME = ''\n",
    "assert((len(PLANET_ID) == 0) ^ (len(SITE_NAME) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.746930Z",
     "start_time": "2022-09-19T22:24:45.744301Z"
    }
   },
   "outputs": [],
   "source": [
    "#Local directory where classification file(s) are located\n",
    "uploadDir = Path(f'planet_images_cropped/{PLANET_ID}').absolute()\n",
    "\n",
    "#Name of classified geotif\n",
    "classified_image_filename = f'classification_{PLANET_ID}.tif' \n",
    "\n",
    "#Uncomment if logfile exists and esnure it is included in filePaths below before upload\n",
    "#log_filename = 'logfile.txt \n",
    "\n",
    "#Uncomment if uploading any additional files and esnure they are included in filePaths below before upload\n",
    "#additional_filename = 'additional_file.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.771895Z",
     "start_time": "2022-09-19T22:24:45.749204Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classified Image read and geometry\n",
    "\n",
    "with rasterio.open(uploadDir / classified_image_filename) as ds:\n",
    "    bounds = ds.bounds\n",
    "    crs_utm = ds.crs\n",
    "    \n",
    "bounds_4326 = transform_bounds(crs_utm, CRS.from_epsg(4326), *bounds)\n",
    "classified_geometry = box(*bounds_4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.819382Z",
     "start_time": "2022-09-19T22:24:45.773570Z"
    }
   },
   "outputs": [],
   "source": [
    "with rasterio.open(uploadDir / classified_image_filename) as ds:\n",
    "    water_mask = ds.read(1)\n",
    "    nodata = ds.nodata\n",
    "    \n",
    "data_mask = (water_mask != nodata)\n",
    "water_frac = (water_mask == 1).sum() / data_mask.sum()\n",
    "print(f'Fraction of water is {water_frac: 1.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.828648Z",
     "start_time": "2022-09-19T22:24:45.821149Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bins = [0, .0008, .02, 1]\n",
    "def stratify(water_frac):\n",
    "    return np.digitize(water_frac, bins, right=True)\n",
    "water_stratum = stratify(water_frac)\n",
    "water_stratum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.834017Z",
     "start_time": "2022-09-19T22:24:45.830197Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "print('Strata for percent water x')\n",
    "print(f'Strata 0: =={bins[0]}%')\n",
    "print(f'Strata 1: {bins[0] * 100} < x <= {bins[1] * 100}%')\n",
    "print(f'Strata 2: {bins[1] * 100} < x <= {bins[2] * 100}%')\n",
    "print(f'Strata 3: x > {bins[2] * 100}%')\n",
    "\n",
    "print()\n",
    "print('Example')\n",
    "for pw in [0, 0.0001, 0.0008, 0.001, 0.01, .03]:\n",
    "    ind = stratify(pw)\n",
    "    print(f'Area with {pw*100}% water is in strata {ind}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:45.838175Z",
     "start_time": "2022-09-19T22:24:45.835591Z"
    }
   },
   "outputs": [],
   "source": [
    "#Name of person who created and edited the classification\n",
    "editor_name = 'Charlie Marshak' \n",
    "\n",
    "#Name of person who reviewed the classification. Leave as None if classification has not been reviewed\n",
    "reviewer_name = '' \n",
    "\n",
    "#Usually 'Mannual classification' or 'Review'\n",
    "calc_type = 'Manual classification' \n",
    "\n",
    "#Change to 'Final' if review is classification passed review with no changes\n",
    "processing_level = 'Intermediate' \n",
    "\n",
    "#Processing notes. e.g. 'Supervised classification using SCP mannual edits using Serval informed by Pekel water mask'\n",
    "notes = 'Updated Water Stratum (CM).'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Credentials\n",
    "In order to download imagery from the private bucket, JPL RSA access and OPERA Calval AWS credenitals are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.139605Z",
     "start_time": "2022-09-19T22:24:45.839952Z"
    }
   },
   "outputs": [],
   "source": [
    "bucket_name = 'opera-calval-database-dswx'\n",
    "session = boto3.session.Session(profile_name='saml-pub')\n",
    "s3 = session.resource('s3')\n",
    "s3_client = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image metadata table\n",
    "To get the geometry metadata for the classified image, we copy the geometry of the source image from the database since the extents are the same. This geometry could also be generated directly from the classified imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.726772Z",
     "start_time": "2022-09-19T22:24:46.143222Z"
    }
   },
   "outputs": [],
   "source": [
    "imageTable = gpd.read_file(s3.Object(bucket_name,'image.geojson').get()['Body'])\n",
    "imagecalcTable = gpd.read_file(s3.Object(bucket_name,'image_calc.geojson').get()['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.732996Z",
     "start_time": "2022-09-19T22:24:46.728456Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = imageTable[['image_name', 'site_name']]\n",
    "df_site2image = temp.set_index('site_name')\n",
    "df_image2site = temp.set_index('image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.739331Z",
     "start_time": "2022-09-19T22:24:46.734549Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell will show the number of planet images found for a given chip. If more than one, ensure the printed Planet\n",
    "# ID matches the planet image used to generate the classification\n",
    "if not PLANET_ID:\n",
    "    values = PLANET_ID = df_site2image.loc[SITE_NAME].tolist()\n",
    "    PLANET_ID = values[0]\n",
    "    print(f'There was {len(values)} planet images for this chip')\n",
    "else:\n",
    "    values = df_image2site.loc[PLANET_ID].tolist()\n",
    "    SITE_NAME = values[0]\n",
    "    print(f'There were {len(values)} chips for this planet_image')\n",
    "\n",
    "(SITE_NAME, PLANET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.746556Z",
     "start_time": "2022-09-19T22:24:46.740891Z"
    }
   },
   "outputs": [],
   "source": [
    "search = imageTable[imageTable.image_name == PLANET_ID]\n",
    "planet_image = search.iloc[[0]]\n",
    "geometry = planet_image.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.754633Z",
     "start_time": "2022-09-19T22:24:46.747994Z"
    }
   },
   "outputs": [],
   "source": [
    "# This cell assigns a version number to the classification. If this is the first classification of a given planet\n",
    "# image, the assigned version should be 0. Otherwise, it will increment on the latest version found in the database\n",
    "search = imagecalcTable[imagecalcTable.image_name == PLANET_ID]\n",
    "if len(search) == 0:\n",
    "    version = 0\n",
    "    previous_name = None\n",
    "    print('first entry into table for ID:'+PLANET_ID+' assigning version = 0')\n",
    "else:\n",
    "    try:\n",
    "        version = search['version'].max() + 1\n",
    "        previous_name = search[search.version==search['version'].max()].image_calc_name.iloc[0]\n",
    "        print('assigning version based on maximum version in table. version = '+str(version))\n",
    "    except:\n",
    "        version = len(search)\n",
    "        previous_name = None\n",
    "        print('could not read version from table. assigned based on number of matching table entries. verson = '+str(version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the required file locations and metadata fields\n",
    "To upload the classified image, we need to specify its location on the local computer (and the location of auxilary files). We also need to fill in some metadata fields. Both file paths and metadata are specified as dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.759781Z",
     "start_time": "2022-09-19T22:24:46.756247Z"
    }
   },
   "outputs": [],
   "source": [
    "uploadDir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.764903Z",
     "start_time": "2022-09-19T22:24:46.761518Z"
    }
   },
   "outputs": [],
   "source": [
    "filePaths = {\n",
    "    'image_calc' : str(uploadDir  / classified_image_filename),\n",
    "    #'logfile' : uploadDir + log_filename, #uncomment this line if uploading logfile\n",
    "    #additional_file: additional_file_name #uncomment this line if uploading additional file\n",
    "}\n",
    "filePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:46.771573Z",
     "start_time": "2022-09-19T22:24:46.766498Z"
    }
   },
   "outputs": [],
   "source": [
    "metaData = {\n",
    "    'image_name':planet_image.image_name.iloc[0], #str\n",
    "    'image_calc_name':planet_image.image_name.iloc[0]+'_classification_v'+str(version), #str \n",
    "    'previous_name':previous_name, #str\n",
    "    'calc_type':calc_type, #str \n",
    "    'processing_level':'Intermediate', #str\n",
    "    'oversight_level':None, #str,\n",
    "    'calculated_by': editor_name, #str\n",
    "    'reviewed_by': None, #str\n",
    "    'notes' : notes,\n",
    "    'version' : version,\n",
    "    'public':True, #bool\n",
    "    'water_stratum': water_stratum,\n",
    "    'geometry':classified_geometry, #shapely geometry\n",
    "}\n",
    "metaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the image\n",
    "We use a pre-defined function to upload files and metadata to the staging area. This function takes the file paths and metadata dictionaries, as well as the AWS session object as inputs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T22:24:48.761168Z",
     "start_time": "2022-09-19T22:24:46.773226Z"
    }
   },
   "outputs": [],
   "source": [
    "addImageCalc(filePaths,metaData,session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dswx_val",
   "language": "python",
   "name": "dswx_val"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
