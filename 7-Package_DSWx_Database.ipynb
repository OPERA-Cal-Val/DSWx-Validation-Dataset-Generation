{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "featured-attitude",
   "metadata": {},
   "source": [
    "Grabbing the latest chips that are being worked on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_calc = gpd.read_file('s3://opera-calval-database-dswx/image_calc.geojson')\n",
    "df_image_calc.dropna(subset='geometry', inplace=True)\n",
    "df_image_calc = df_image_calc.sort_values(by=['image_name', 'upload_date'], ascending=True)\n",
    "df_image_calc = df_image_calc.groupby('image_name').tail(1)\n",
    "df_image_calc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = df_image_calc[df_image_calc.processing_level == 'Intermediate'].shape[0]\n",
    "n = df_image_calc.shape[0]\n",
    "f'We have submitted {n} images currently'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-disco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-22T20:20:01.966971Z",
     "start_time": "2022-09-22T20:20:01.964736Z"
    }
   },
   "source": [
    "# Extract Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_local_name(row) -> tuple:\n",
    "    s3_bucket = row['bucket']\n",
    "    \n",
    "    s3_keys = row['s3_keys']\n",
    "    l = s3_keys.split(',')\n",
    "    if len(l) > 1:\n",
    "        l = list(filter(lambda key: ('.tif' in key) and ('diff' not in key), l))\n",
    "        if len(l) > 1:\n",
    "            print(l)\n",
    "    s3_key = l[0]\n",
    "    \n",
    "    directory = s3_bucket + '/' + '/'.join(s3_key.split('/')[:-1])\n",
    "    filename = s3_key.split('/')[-1]\n",
    "    return s3_key, directory, filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-sitting",
   "metadata": {},
   "source": [
    "Source: https://stackoverflow.com/questions/22799300/how-to-unpack-a-series-of-tuples-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_image_calc.aggregate(format_local_name, axis=1)\n",
    "df_image_calc[['s3_key', 'directory', 'filename']] = out.apply(pd.Series)\n",
    "df_image_calc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-regulation",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one(src_bucket: str, \n",
    "                 src_key: str, \n",
    "                 dst_dir_path: str, \n",
    "                 dst_filename: str) -> Path:\n",
    "    dst_dir = Path(dst_dir_path)\n",
    "    dst_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    with rasterio.open(f's3://{src_bucket}/{src_key}') as ds:\n",
    "        X = ds.read()\n",
    "        p = ds.profile\n",
    "        \n",
    "    out_path = f'{dst_dir_path}/{dst_filename}'\n",
    "    with rasterio.open(f'{dst_dir_path}/{dst_filename}', 'w', **p) as ds:\n",
    "        ds.write(X)\n",
    "    return out_path\n",
    "\n",
    "def download_one_from_record(data_record: dict) -> Path:\n",
    "    src_bucket = data_record['bucket']\n",
    "    src_key = data_record['s3_key']\n",
    "    \n",
    "    dir_path = data_record['directory']\n",
    "    filename = data_record['filename']\n",
    "    \n",
    "    return download_one(src_bucket, src_key, dir_path, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = df_image_calc.to_dict('records')\n",
    "paths = list(map(download_one_from_record, tqdm(records)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = paths[0].split('/')[0]\n",
    "df_image_calc.to_file(f'{top_dir}/image_calc.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-mentor",
   "metadata": {},
   "source": [
    "# Zip\n",
    "\n",
    "Zips up the download and removes the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(top_dir, 'zip', top_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    shutil.rmtree(top_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
