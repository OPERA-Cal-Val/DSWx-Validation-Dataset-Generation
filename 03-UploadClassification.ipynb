{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Staging Upload to ImageCalc Table\n",
    "This notebook goes through an example of uploading a classified planet image, a logfile, and training data to the DSWx calval database. Data files and metadata are uploading to a staging bucket. Then, the database manager will commit these uploads to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.insert(0, './tools/')\n",
    "from addImageCalc import addImageCalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local directory where classification file(s) are located\n",
    "uploadDir = '/Users/mbonnema/Documents/OPERA_calval/DSWx/FakeChip/' \n",
    "\n",
    "#Name of classified geotif\n",
    "classified_image_filename = 'Fake_2_1_mannualedits.tif' \n",
    "\n",
    "#Uncomment if logfile exists and esnure it is included in filePaths below before upload\n",
    "#log_filename = 'logfile.txt \n",
    "\n",
    "#Uncomment if uploading any additional files and esnure they are included in filePaths below before upload\n",
    "#additional_filename = 'additional_file.txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only specify one. Leave the other as ''. If more than one planet image for given chip, PLANET_ID must be specified \n",
    "PLANET_ID = ''\n",
    "SITE_NAME = '2_1'\n",
    "assert((len(PLANET_ID) == 0) ^ (len(SITE_NAME) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of person who created and edited the classification\n",
    "editor_name = 'Matthew Bonnema' \n",
    "\n",
    "#Name of person who reviewed the classification. Leave as None if classification has not been reviewed\n",
    "reviewer_name = None \n",
    "\n",
    "#Usually 'Mannual classification' or 'Review'\n",
    "calc_type = 'TEST' \n",
    "\n",
    "#Change to 'Final' if review is classification passed review with no changes\n",
    "processing_level = 'Intermediate' \n",
    "\n",
    "#Processing notes. e.g. 'Supervised classification using SCP mannual edits using Serval informed by Pekel water mask'\n",
    "notes = 'This is a fake entry for testing. Delete when testing is complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Credentials\n",
    "In order to download imagery from the private bucket, JPL RSA access and OPERA Calval AWS credenitals are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'opera-calval-database-dswx'\n",
    "session = boto3.session.Session(profile_name='saml-pub')\n",
    "s3 = session.resource('s3')\n",
    "s3_client = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image metadata table\n",
    "To get the geometry metadata for the classified image, we copy the geometry of the source image from the database since the extents are the same. This geometry could also be generated directly from the classified imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTable = gpd.read_file(s3.Object(bucket_name,'image.geojson').get()['Body'])\n",
    "imagecalcTable = gpd.read_file(s3.Object(bucket_name,'image_calc.geojson').get()['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = imageTable[['image_name', 'site_name']]\n",
    "df_site2image = temp.set_index('site_name')\n",
    "df_image2site = temp.set_index('image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was 1 planet images for this chip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2_1', '20210928_141837_16_2407')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell will show the number of planet images found for a given chip. If more than one, ensure the printed Planet\n",
    "# ID matches the planet image used to generate the classification\n",
    "if not PLANET_ID:\n",
    "    values = PLANET_ID = df_site2image.loc[SITE_NAME].tolist()\n",
    "    PLANET_ID = values[0]\n",
    "    print(f'There was {len(values)} planet images for this chip')\n",
    "else:\n",
    "    values = df_image2site.loc[PLANET_ID].tolist()\n",
    "    SITE_NAME = values[0]\n",
    "    print(f'There were {len(values)} chips for this planet_image')\n",
    "\n",
    "(SITE_NAME, PLANET_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = imageTable[imageTable.image_name == PLANET_ID]\n",
    "planet_image = search.iloc[[0]]\n",
    "geometry = planet_image.geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first entry into table for ID:20210928_141837_16_2407 assigning version = 0\n"
     ]
    }
   ],
   "source": [
    "# This cell assigns a version number to the classification. If this is the first classification of a given planet\n",
    "# image, the assigned version should be 0. Otherwise, it will increment on the latest version found in the database\n",
    "search = imagecalcTable[imagecalcTable.image_name == PLANET_ID]\n",
    "if len(search) == 0:\n",
    "    version = 0\n",
    "    previous_name = None\n",
    "    print('first entry into table for ID:'+PLANET_ID+' assigning version = 0')\n",
    "else:\n",
    "    try:\n",
    "        version = search['version'].max() + 1\n",
    "        previous_name = search[search.version==search['version'].max()].image_calc_name.iloc[0]\n",
    "        print('assigning version based on maximum version in table. version = '+str(version))\n",
    "    except:\n",
    "        version = len(search)\n",
    "        previous_name = None\n",
    "        print('could not read version from table. assigned based on number of matching table entries. verson = '+str(version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the required file locations and metadata fields\n",
    "To upload the classified image, we need to specify its location on the local computer (and the location of auxilary files). We also need to fill in some metadata fields. Both file paths and metadata are specified as dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = {\n",
    "    'image_calc' : uploadDir + classified_image_filename,\n",
    "    #'logfile' : uploadDir + log_filename, #uncomment this line if uploading logfile\n",
    "    #additional_file: additional_file_name #uncomment this line if uploading additional file\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_name': '20210928_141837_16_2407',\n",
       " 'image_calc_name': '20210928_141837_16_2407_classification_v0',\n",
       " 'previous_name': None,\n",
       " 'calc_type': 'TEST',\n",
       " 'processing_level': 'Intermediate',\n",
       " 'oversight_level': None,\n",
       " 'calculated_by': 'Matthew Bonnema',\n",
       " 'reviewed_by': None,\n",
       " 'notes': 'This is a fake entry for testing. Delete when testing is complete',\n",
       " 'version': 0,\n",
       " 'public': True,\n",
       " 'geometry': <shapely.geometry.polygon.Polygon at 0x7fad3bcc1990>}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData = {\n",
    "    'image_name':planet_image.image_name.iloc[0], #str\n",
    "    'image_calc_name':planet_image.image_name.iloc[0]+'_classification_v'+str(version), #str \n",
    "    'previous_name':previous_name, #str\n",
    "    'calc_type':calc_type, #str \n",
    "    'processing_level':'Intermediate', #str\n",
    "    'oversight_level':None, #str,\n",
    "    'calculated_by': editor_name, #str\n",
    "    'reviewed_by': None, #str\n",
    "    'notes' : notes,\n",
    "    'version' : version,\n",
    "    'public':True, #bool\n",
    "    'geometry':geometry, #shapely geometry\n",
    "}\n",
    "metaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the image\n",
    "We use a pre-defined function to upload files and metadata to the staging area. This function takes the file paths and metadata dictionaries, as well as the AWS session object as inputs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating geojson table\n",
      "Uploading geojson table\n",
      "Uploading files\n",
      "staging complete\n"
     ]
    }
   ],
   "source": [
    "addImageCalc(filePaths,metaData,session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
